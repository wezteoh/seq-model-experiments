# Minimal, fast debug run on CPU
wandb:
  project: transformer-mnist
  name: dryrun

train:
  seed: 0
  validate_at_start: true
  test: false
  ckpt: null
  ckpt_dir: ~/ckpt

# Lightning Trainer
trainer:
  accelerator: cpu
  devices: 1
  precision: bf16-true
  max_epochs: 1
  fast_dev_run: true           # one batch train/val/test and exit
  limit_train_batches: 2       # safety; only a couple batches
  limit_val_batches: 1
  limit_test_batches: 0
  log_every_n_steps: 1
  enable_checkpointing: false

task:
  name: MNISTGenerationTask
  target_type: token
  input_type: value
  loss: cross_entropy
  data_mean: 0.0
  data_std: 1.0

dataset:
  name: MNISTSequenceGenerationDataModule
  bsz: 8
  num_workers: 0
  data_dir: ~/data

metrics:
  loss: null
  accuracy: null

# Small model for speed (used by CPU class after the code tweak below)
model:
  name: transformer
  args:
    context_length: 785 # include padded prefix
    n_layer: 4
    d_model: 128
    n_head: 4
    d_ff: 256
    use_rope: True
    theta: 10000.0
    input_type: value
    output_type: logit
    vocab_size: 256
    n_encoder_layer: 1
    input_value_size: 1

# Optimizer
optimizer:
  lr: 0.001
  weight_decay: 0.01
  lr_schedule:
    div_factor: 15
    final_div_factor: 500
    pct_start: 0.1
    total_steps: null

callbacks:
  ImagePrefixSamplerCallback:
    num_samples: 4
    every_n_epochs: 1
    sample_prefix_length: 256
    max_length: 784